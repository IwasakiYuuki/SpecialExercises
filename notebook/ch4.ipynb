{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_openml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Affine:\n",
    "    def __init__(self, w, b):\n",
    "        self.w = w\n",
    "        self.b = b\n",
    "        self.dw = None\n",
    "        self.db = None\n",
    "        self.input = None\n",
    "    \n",
    "    def forward(self, x):\n",
    "        self.input = x\n",
    "        y = np.dot(self.w, x) + self.b\n",
    "        return y\n",
    "    \n",
    "    def backward(self, dx):\n",
    "        self.dw = np.dot(dx ,self.input.T)\n",
    "        self.db = np.sum(dx, axis=1, keepdims=True)\n",
    "        return np.dot(self.w.T, dx)\n",
    "    \n",
    "    def update(self, lr=0.1):\n",
    "        self.w -= self.dw * lr\n",
    "        self.b -= self.db * lr\n",
    "    \n",
    "class Sigmoid:\n",
    "    def __init__(self):\n",
    "        self.output = None\n",
    "        \n",
    "    def forward(self, x):\n",
    "        y = 1 / (1 + np.exp(-x))\n",
    "        self.output = y\n",
    "        return y\n",
    "    \n",
    "    def backward(self, dx):\n",
    "        return dx * self.output * (1.0 - self.output)\n",
    "    \n",
    "class MSE:\n",
    "    def __init__(self):\n",
    "        self.output = None\n",
    "        self.t = None\n",
    "    \n",
    "    def forward(self, z, t):\n",
    "        data_num = z.shape[-1]\n",
    "        loss = np.sum((z - t) ** 2) / (2 * data_num)\n",
    "        self.z = z\n",
    "        self.t = t\n",
    "        return loss\n",
    "    \n",
    "    def backward(self):\n",
    "        return self.z - self.t\n",
    "    \n",
    "class SigmoidAndCrossEntropy:\n",
    "    def __init__(self):\n",
    "        self.y = None\n",
    "        self.t = None\n",
    "        \n",
    "    def forward(self, x, t):\n",
    "        y = 1 / (1 + np.exp(-x))\n",
    "        data_num = y.shape[-1]\n",
    "        loss = -1 * (t * np.log(y) + (1 - t) * np.log(1 - y)).mean()\n",
    "        self.y = y\n",
    "        self.t = t\n",
    "        return loss\n",
    "        \n",
    "    def backward(self):\n",
    "        return self.y - self.t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise4.1-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 loss 0.706575883796967 y [[0.587688   0.53509165 0.58682017 0.54249822]]\n",
      "epoch 100 loss 0.6904405173924182 y [[0.50075134 0.52039929 0.47843631 0.49171858]]\n",
      "epoch 200 loss 0.21629958627642565 y [[0.20741608 0.88634178 0.72301019 0.17118378]]\n",
      "epoch 300 loss 0.0234047518994882 y [[0.02277354 0.97216757 0.97750472 0.01941201]]\n",
      "epoch 400 loss 0.011920514314600485 y [[0.01151172 0.9850331  0.98898454 0.00989765]]\n",
      "epoch 500 loss 0.007947573541286022 y [[0.0076516  0.98983841 0.99275481 0.00660224]]\n",
      "epoch 600 loss 0.005946770652306348 y [[0.00571502 0.99232783 0.99461493 0.00494204]]\n",
      "epoch 700 loss 0.004745125096296916 y [[0.00455449 0.99384518 0.99571994 0.00394472]]\n",
      "epoch 800 loss 0.003944749204570458 y [[0.00378266 0.99486506 0.99645101 0.00328031]]\n",
      "epoch 900 loss 0.0033739198761100543 y [[0.00323279 0.99559694 0.99697005 0.00280637]]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[0, 0, 1, 1],\n",
    "              [0, 1, 0, 1]])\n",
    "t = np.array([0, 1, 1, 0])\n",
    "\n",
    "input_dim = 2\n",
    "hidden_dim = 2\n",
    "output_dim = 1\n",
    "\n",
    "w = 2.0 * np.random.rand(hidden_dim, input_dim) - 1.0\n",
    "b = 2.0 * np.random.rand(hidden_dim, 1) - 1.0\n",
    "u = 2.0 * np.random.rand(output_dim, hidden_dim) -1.0\n",
    "c = 2.0 * np.random.rand(output_dim, 1) - 1.0\n",
    "\n",
    "layer1 = Affine(w, b)\n",
    "layer2 = Sigmoid()\n",
    "layer3 = Affine(u, c)\n",
    "layer4 = SigmoidAndCrossEntropy()\n",
    "\n",
    "epoch = 1000\n",
    "for i in range(epoch):\n",
    "    p = layer1.forward(x)\n",
    "    y = layer2.forward(p)\n",
    "    q = layer3.forward(y)\n",
    "    loss = layer4.forward(q, t)\n",
    "    \n",
    "    dq = layer4.backward()\n",
    "    dy = layer3.backward(dq)\n",
    "    dp = layer2.backward(dy)\n",
    "    dx = layer1.backward(dp)\n",
    "    \n",
    "    layer1.update()\n",
    "    layer3.update()\n",
    "    \n",
    "    if i % 100 == 0:\n",
    "        print('epoch', i, 'loss', loss, 'y', layer4.y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise4.1-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 loss 0.7424335089477943 y [[0.30996943 0.28534938 0.45070116 0.42173493]]\n",
      "epoch 100 loss 0.6931471805599454 y [[0.5 0.5 0.5 0.5]]\n",
      "epoch 200 loss 0.6931471805599452 y [[0.5 0.5 0.5 0.5]]\n",
      "epoch 300 loss 0.6931471805599453 y [[0.5 0.5 0.5 0.5]]\n",
      "epoch 400 loss 0.6931471805599453 y [[0.5 0.5 0.5 0.5]]\n",
      "epoch 500 loss 0.6931471805599453 y [[0.5 0.5 0.5 0.5]]\n",
      "epoch 600 loss 0.6931471805599453 y [[0.5 0.5 0.5 0.5]]\n",
      "epoch 700 loss 0.6931471805599453 y [[0.5 0.5 0.5 0.5]]\n",
      "epoch 800 loss 0.6931471805599453 y [[0.5 0.5 0.5 0.5]]\n",
      "epoch 900 loss 0.6931471805599453 y [[0.5 0.5 0.5 0.5]]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[0, 0, 1, 1],\n",
    "              [0, 1, 0, 1]])\n",
    "t = np.array([0, 1, 1, 0])\n",
    "\n",
    "input_dim = 2\n",
    "output_dim = 1\n",
    "\n",
    "w = 2.0 * np.random.rand(output_dim, input_dim) - 1.0\n",
    "b = 2.0 * np.random.rand(output_dim, 1) - 1.0\n",
    "\n",
    "\n",
    "layer1 = Affine(w, b)\n",
    "layer2 = SigmoidAndCrossEntropy()\n",
    "\n",
    "epoch = 1000\n",
    "for i in range(epoch):\n",
    "    p = layer1.forward(x)\n",
    "    loss = layer2.forward(p, t)\n",
    "    \n",
    "    dp = layer2.backward()\n",
    "    dx = layer1.backward(dp)\n",
    "    \n",
    "    layer1.update()\n",
    "    \n",
    "    if i % 100 == 0:\n",
    "        print('epoch', i, 'loss', loss, 'y', layer2.y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise4.1-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 loss 0.7569672267475516 y [[0.68545861 0.6991134  0.6918391  0.70733958 0.63240986 0.64532427\n",
      "  0.64019012 0.65242227]]\n",
      "epoch 100 loss 0.7073718682628555 y [[0.53652657 0.59627517 0.60144254 0.61633766 0.59582246 0.6147338\n",
      "  0.61597021 0.62012729]]\n",
      "epoch 200 loss 0.6724121053595216 y [[0.27892378 0.9027918  0.93097588 0.78106731 0.90232495 0.74981821\n",
      "  0.7807005  0.70198355]]\n",
      "epoch 300 loss 0.2946331684145387 y [[0.0154804  0.98377857 0.98341429 0.26103761 0.98371482 0.26104629\n",
      "  0.26099229 0.25045144]]\n",
      "epoch 400 loss 0.15213501825753073 y [[0.01807941 0.98631608 0.98653915 0.18770692 0.9864161  0.19438622\n",
      "  0.18458219 0.58876505]]\n",
      "epoch 500 loss 0.018658455420743073 y [[0.00813286 0.99146177 0.99143895 0.01927338 0.99147439 0.01926457\n",
      "  0.01927361 0.94460283]]\n",
      "epoch 600 loss 0.009111424717798097 y [[0.00623282 0.99464088 0.99461915 0.00893111 0.99464553 0.00892677\n",
      "  0.0089311  0.9766841 ]]\n",
      "epoch 700 loss 0.006058859138923263 y [[0.00494459 0.99609562 0.99607875 0.00573614 0.9960983  0.00573344\n",
      "  0.00573606 0.98559622]]\n",
      "epoch 800 loss 0.004541127287450968 y [[0.00406436 0.99692887 0.9969156  0.0042048  0.9969307  0.00420288\n",
      "  0.00420472 0.98967533]]\n",
      "epoch 900 loss 0.0036303120997505196 y [[0.00343882 0.99746968 0.99745898 0.00331059 0.99747104 0.00330913\n",
      "  0.00331051 0.99199113]]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[0, 0, 0, 0, 1, 1, 1, 1],\n",
    "              [0, 0, 1, 1, 0, 0, 1, 1],\n",
    "              [0, 1, 0, 1, 0, 1, 0, 1]])\n",
    "t = np.array([0, 1, 1, 0, 1, 0, 0, 1])\n",
    "\n",
    "input_dim = 3\n",
    "hidden_dim = 3\n",
    "output_dim = 1\n",
    "\n",
    "w = 2.0 * np.random.rand(hidden_dim, input_dim) - 1.0\n",
    "b = 2.0 * np.random.rand(hidden_dim, 1) - 1.0\n",
    "u = 2.0 * np.random.rand(output_dim, hidden_dim) -1.0\n",
    "c = 2.0 * np.random.rand(output_dim, 1) - 1.0\n",
    "\n",
    "layer1 = Affine(w, b)\n",
    "layer2 = Sigmoid()\n",
    "layer3 = Affine(u, c)\n",
    "layer4 = SigmoidAndCrossEntropy()\n",
    "\n",
    "epoch = 1000\n",
    "for i in range(epoch):\n",
    "    p = layer1.forward(x)\n",
    "    y = layer2.forward(p)\n",
    "    q = layer3.forward(y)\n",
    "    loss = layer4.forward(q, t)\n",
    "    \n",
    "    dq = layer4.backward()\n",
    "    dy = layer3.backward(dq)\n",
    "    dp = layer2.backward(dy)\n",
    "    dx = layer1.backward(dp)\n",
    "    \n",
    "    layer1.update()\n",
    "    layer3.update()\n",
    "    \n",
    "    if i % 100 == 0:\n",
    "        print('epoch', i, 'loss', loss, 'y', layer4.y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise4.1-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 loss 0.9147069950881772 y [[0.18132317 0.20212241 0.19277975 0.2141089  0.18903368 0.21034223\n",
      "  0.20094485 0.22196107]]\n",
      "epoch 100 loss 0.6799459912079164 y [[0.2238357  0.41961782 0.42089837 0.44748853 0.4176084  0.44611058\n",
      "  0.44698556 0.4480957 ]]\n",
      "epoch 200 loss 0.31889976174503487 y [[0.04768285 0.95429884 0.95419229 0.27965573 0.95431132 0.279603\n",
      "  0.27965005 0.25210487]]\n",
      "epoch 300 loss 0.29268989371340814 y [[0.01671347 0.98719876 0.98717467 0.25770721 0.98720166 0.2576925\n",
      "  0.25770563 0.24858294]]\n",
      "epoch 400 loss 0.2878071102047187 y [[0.00976738 0.99276831 0.99275731 0.25432396 0.99276964 0.25431711\n",
      "  0.25432322 0.2489568 ]]\n",
      "epoch 500 loss 0.2857938320621163 y [[0.00684852 0.99501346 0.99500686 0.25297237 0.99501426 0.25296831\n",
      "  0.25297193 0.24919429]]\n",
      "epoch 600 loss 0.28470357514924327 y [[0.00525623 0.99621417 0.99620964 0.25225178 0.99621472 0.25224905\n",
      "  0.25225148 0.24934629]]\n",
      "epoch 700 loss 0.2840225558607353 y [[0.00425744 0.99695782 0.99695446 0.25180624 0.99695823 0.25180427\n",
      "  0.25180603 0.24945081]]\n",
      "epoch 800 loss 0.2835578098442147 y [[0.00357388 0.99746207 0.99745944 0.25150448 0.99746239 0.25150298\n",
      "  0.25150432 0.24952692]]\n",
      "epoch 900 loss 0.2832209220542392 y [[0.00307729 0.99782575 0.9978236  0.25128705 0.99782601 0.25128586\n",
      "  0.25128692 0.24958481]]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[0, 0, 0, 0, 1, 1, 1, 1],\n",
    "              [0, 0, 1, 1, 0, 0, 1, 1],\n",
    "              [0, 1, 0, 1, 0, 1, 0, 1]])\n",
    "t = np.array([0, 1, 1, 0, 1, 0, 0, 1])\n",
    "\n",
    "input_dim = 3\n",
    "hidden_dim = 2\n",
    "output_dim = 1\n",
    "\n",
    "w = 2.0 * np.random.rand(hidden_dim, input_dim) - 1.0\n",
    "b = 2.0 * np.random.rand(hidden_dim, 1) - 1.0\n",
    "u = 2.0 * np.random.rand(output_dim, hidden_dim) -1.0\n",
    "c = 2.0 * np.random.rand(output_dim, 1) - 1.0\n",
    "\n",
    "layer1 = Affine(w, b)\n",
    "layer2 = Sigmoid()\n",
    "layer3 = Affine(u, c)\n",
    "layer4 = SigmoidAndCrossEntropy()\n",
    "\n",
    "epoch = 1000\n",
    "for i in range(epoch):\n",
    "    p = layer1.forward(x)\n",
    "    y = layer2.forward(p)\n",
    "    q = layer3.forward(y)\n",
    "    loss = layer4.forward(q, t)\n",
    "    \n",
    "    dq = layer4.backward()\n",
    "    dy = layer3.backward(dq)\n",
    "    dp = layer2.backward(dy)\n",
    "    dx = layer1.backward(dp)\n",
    "    \n",
    "    layer1.update()\n",
    "    layer3.update()\n",
    "    \n",
    "    if i % 100 == 0:\n",
    "        print('epoch', i, 'loss', loss, 'y', layer4.y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise4.1-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 loss 0.7553541323511623 y [[0.50464905 0.65204633 0.61957603 0.74973485 0.39398684 0.54459751\n",
      "  0.50964084 0.65656362]\n",
      " [0.45240716 0.57220675 0.27511962 0.3806027  0.30495321 0.41532105\n",
      "  0.16774805 0.24603684]]\n",
      "epoch 100 loss 1.6560977441839155 y [[0.85757581 0.93908255 0.939082   0.97528834 0.93907841 0.97528683\n",
      "  0.9752866  0.99019947]\n",
      " [0.1424422  0.06092417 0.06091703 0.02471053 0.06091784 0.02471087\n",
      "  0.02470786 0.00979801]]\n",
      "epoch 200 loss 1.6560541576131014 y [[0.85759341 0.93908164 0.93908164 0.97528433 0.93908164 0.97528433\n",
      "  0.97528433 0.990197  ]\n",
      " [0.14240664 0.06091836 0.06091836 0.02471566 0.06091836 0.02471566\n",
      "  0.02471566 0.00980299]]\n",
      "epoch 300 loss 1.6560540436134215 y [[0.85759345 0.93908164 0.93908164 0.97528433 0.93908164 0.97528433\n",
      "  0.97528433 0.990197  ]\n",
      " [0.14240655 0.06091836 0.06091836 0.02471567 0.06091836 0.02471567\n",
      "  0.02471567 0.009803  ]]\n",
      "epoch 400 loss 1.65605404331527 y [[0.85759345 0.93908164 0.93908164 0.97528433 0.93908164 0.97528433\n",
      "  0.97528433 0.990197  ]\n",
      " [0.14240655 0.06091836 0.06091836 0.02471567 0.06091836 0.02471567\n",
      "  0.02471567 0.009803  ]]\n",
      "epoch 500 loss 1.6560540433144892 y [[0.85759345 0.93908164 0.93908164 0.97528433 0.93908164 0.97528433\n",
      "  0.97528433 0.990197  ]\n",
      " [0.14240655 0.06091836 0.06091836 0.02471567 0.06091836 0.02471567\n",
      "  0.02471567 0.009803  ]]\n",
      "epoch 600 loss 1.6560540433144886 y [[0.85759345 0.93908164 0.93908164 0.97528433 0.93908164 0.97528433\n",
      "  0.97528433 0.990197  ]\n",
      " [0.14240655 0.06091836 0.06091836 0.02471567 0.06091836 0.02471567\n",
      "  0.02471567 0.009803  ]]\n",
      "epoch 700 loss 1.6560540433144886 y [[0.85759345 0.93908164 0.93908164 0.97528433 0.93908164 0.97528433\n",
      "  0.97528433 0.990197  ]\n",
      " [0.14240655 0.06091836 0.06091836 0.02471567 0.06091836 0.02471567\n",
      "  0.02471567 0.009803  ]]\n",
      "epoch 800 loss 1.6560540433144886 y [[0.85759345 0.93908164 0.93908164 0.97528433 0.93908164 0.97528433\n",
      "  0.97528433 0.990197  ]\n",
      " [0.14240655 0.06091836 0.06091836 0.02471567 0.06091836 0.02471567\n",
      "  0.02471567 0.009803  ]]\n",
      "epoch 900 loss 1.6560540433144886 y [[0.85759345 0.93908164 0.93908164 0.97528433 0.93908164 0.97528433\n",
      "  0.97528433 0.990197  ]\n",
      " [0.14240655 0.06091836 0.06091836 0.02471567 0.06091836 0.02471567\n",
      "  0.02471567 0.009803  ]]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[0, 0, 0, 0, 1, 1, 1, 1],\n",
    "              [0, 0, 1, 1, 0, 0, 1, 1],\n",
    "              [0, 1, 0, 1, 0, 1, 0, 1]])\n",
    "t = np.array([0, 1, 1, 0, 1, 0, 0, 1])\n",
    "\n",
    "input_dim = 3\n",
    "output_dim = 1\n",
    "\n",
    "w = 2.0 * np.random.rand(hidden_dim, input_dim) - 1.0\n",
    "b = 2.0 * np.random.rand(hidden_dim, 1) - 1.0\n",
    "\n",
    "layer1 = Affine(w, b)\n",
    "layer2 = SigmoidAndCrossEntropy()\n",
    "\n",
    "epoch = 1000\n",
    "for i in range(epoch):\n",
    "    p = layer1.forward(x)\n",
    "    loss = layer2.forward(p, t)\n",
    "    \n",
    "    dp = layer2.backward()\n",
    "    dx = layer1.backward(dp)\n",
    "    \n",
    "    layer1.update()\n",
    "    \n",
    "    if i % 100 == 0:\n",
    "        print('epoch', i, 'loss', loss, 'y', layer2.y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise4.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNISTデータダウンロード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.path.join(os.path.abspath('..'), 'data')\n",
    "if not os.path.exists(data_dir):\n",
    "    os.makedirs(data_dir)\n",
    "\n",
    "X, Y = fetch_openml('mnist_784', data_home=data_dir, return_X_y=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学習設定・データローダー実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y = (X[:60000], Y[:60000])\n",
    "test_x, test_y = (X[60000:], Y[60000:])\n",
    "\n",
    "train_y = np.identity(10)[train_y.astype(np.int)]\n",
    "test_y = np.identity(10)[test_y.astype(np.int)]\n",
    "\n",
    "epochs = 10\n",
    "batch_size = 100\n",
    "\n",
    "input_dim = 784\n",
    "hidden_dim = 10\n",
    "output_dim = 10\n",
    "\n",
    "class DataLoader:\n",
    "    def __init__(self, inputs, outputs, batch_size=100):\n",
    "        if not isinstance(inputs, np.ndarray):\n",
    "            raise TypeError('{} must be numpy.ndarray'.format('inputs'))\n",
    "        if not isinstance(outputs, np.ndarray):\n",
    "            raise TypeError('{} must be numpy.ndarray'.format('outputs'))\n",
    "        if inputs.shape[0] != outputs.shape[0]:\n",
    "            raise ValueError('The shapes of inputs and outputs must be same.')\n",
    "        self._inputs = inputs\n",
    "        self._outputs = outputs\n",
    "        self._batch_size = batch_size\n",
    "        self._i = 0\n",
    "        \n",
    "    def __iter__(self):\n",
    "        return self\n",
    "    \n",
    "    def __next__(self):\n",
    "        if (self._i * self._batch_size) >= len(self._inputs):\n",
    "            raise StopIteration()\n",
    "        \n",
    "        if ((self._i + 1) * self._batch_size) < len(self._inputs):\n",
    "            x, y = self._inputs[self._i * self._batch_size:(self._i + 1) * self._batch_size], \\\n",
    "                self._outputs[self._i * self._batch_size:(self._i + 1) * self._batch_size]\n",
    "        else:\n",
    "            x, y = self._inputs[self._i * self._batch_size:], \\\n",
    "                self._outputs[self._i * self._batch_size:]\n",
    "        self._i += 1\n",
    "        \n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### モデル学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-64-4d0c4e1674f9>:28: RuntimeWarning: overflow encountered in exp\n",
      "  y = 1 / (1 + np.exp(-x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 loss:0.002510053070384594\n",
      "epoch:1 loss:0.0009945945638161454\n",
      "epoch:2 loss:0.0005158744987348487\n",
      "epoch:3 loss:0.000338962218386652\n",
      "epoch:4 loss:0.0002395038986965784\n",
      "epoch:5 loss:0.00013654707009375124\n",
      "epoch:6 loss:0.00014226613123414448\n",
      "epoch:7 loss:0.00011749993955195664\n",
      "epoch:8 loss:0.0001325618325690182\n",
      "epoch:9 loss:9.852824521709377e-05\n"
     ]
    }
   ],
   "source": [
    "w = 2.0 * np.random.rand(hidden_dim, input_dim) - 1.0\n",
    "b = 2.0 * np.random.rand(hidden_dim, 1) - 1.0\n",
    "u = 2.0 * np.random.rand(output_dim, hidden_dim) -1.0\n",
    "c = 2.0 * np.random.rand(output_dim, 1) - 1.0\n",
    "\n",
    "layer1 = Affine(w, b)\n",
    "layer2 = Sigmoid()\n",
    "layer3 = Affine(u, c)\n",
    "layer4 = Sigmoid()\n",
    "layer5 = MSE()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for x, y in DataLoader(train_x, train_y, batch_size=batch_size):\n",
    "        p = layer1.forward(x.T)\n",
    "        y = layer2.forward(p)\n",
    "        q = layer3.forward(y)\n",
    "        z = layer4.forward(q)\n",
    "        loss = layer5.forward(z, y)\n",
    "        \n",
    "        dz = layer5.backward()\n",
    "        dq = layer4.backward(dz)\n",
    "        dy = layer3.backward(dq)\n",
    "        dp = layer2.backward(dy)\n",
    "        dx = layer1.backward(dp)\n",
    "        \n",
    "        layer1.update()\n",
    "        layer3.update()\n",
    "    print('epoch:{epoch} loss:{loss}'.format(epoch=epoch, loss=loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### モデル推論"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isinstance([0], np.ndarray)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
